# 多用户数据隔离功能说明

## ✨ 新功能概述

线上版本现在支持**多用户数据隔离**和**自动清理过期数据**功能！

### 主要特性

✅ **用户数据隔离**：每个用户只能看到自己上传的简历  
✅ **自动清理**：数据在1小时后自动删除  
✅ **基于 Session**：使用 Flask Session 识别用户  
✅ **后台任务**：每10分钟自动清理过期数据  

## 🔐 工作原理

### 1. 用户识别机制

**方案选择**：使用 **Flask Session ID** 而非 IP 地址

| 识别方式 | 优点 | 缺点 | 是否采用 |
|---------|------|------|---------|
| IP 地址 | 简单 | ❌ 多人共享IP<br>❌ 用户换网络丢失数据 | ❌ 不采用 |
| Session ID | ✅ 准确识别单个用户<br>✅ 跨页面持久化<br>✅ Flask 内置支持 | 需要配置 session | ✅ **采用** |

### 2. Session 配置

```python
# Flask Session 配置
app.config['SECRET_KEY'] = secrets.token_hex(32)
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(hours=1)
```

- **SECRET_KEY**：用于加密 session cookie（生产环境建议配置环境变量）
- **SESSION 过期时间**：1小时

### 3. 用户数据流程

```
用户访问
    ↓
自动生成 Session ID
    ↓
上传PDF文件
    ↓
数据关联到 Session ID
    ↓
只能查看自己的数据
    ↓
1小时后自动清理
```

## 🗄️ 数据库变更

### 新增字段

```sql
CREATE TABLE resumes (
    id INTEGER PRIMARY KEY,
    session_id TEXT NOT NULL,          -- 新增：用户Session ID
    filename TEXT NOT NULL,
    name TEXT,
    email TEXT,
    undergraduate_school TEXT,
    graduate_school TEXT,
    current_grade TEXT,
    created_at TIMESTAMP,              -- 用于判断是否过期
    updated_at TIMESTAMP
);

-- 新增索引提高查询性能
CREATE INDEX idx_session_id ON resumes(session_id);
CREATE INDEX idx_created_at ON resumes(created_at);
```

## 🕒 自动清理机制

### 后台定时任务

使用 **APScheduler** 实现定时清理：

```python
from apscheduler.schedulers.background import BackgroundScheduler

scheduler = BackgroundScheduler()
scheduler.add_job(
    func=lambda: db.clean_expired_data(hours=1),
    trigger="interval",
    minutes=10  # 每10分钟执行一次
)
scheduler.start()
```

### 清理逻辑

```python
def clean_expired_data(self, hours: int = 1):
    """清理超过指定小时数的数据"""
    expire_time = datetime.now() - timedelta(hours=hours)
    
    DELETE FROM resumes 
    WHERE created_at < expire_time
```

## 📊 API 变更

### 修改的接口

所有数据查询接口现在都自动过滤当前用户的数据：

#### 1. 获取简历列表
```python
# 旧版：返回所有用户的数据
GET /api/resumes

# 新版：只返回当前用户的数据
GET /api/resumes
→ 自动根据 session_id 过滤
```

#### 2. 获取邮箱列表
```python
# 旧版：返回所有用户的邮箱
GET /api/emails

# 新版：只返回当前用户的邮箱
GET /api/emails
→ 自动根据 session_id 过滤
```

#### 3. 清空数据
```python
# 旧版：清空整个数据库
POST /api/clear

# 新版：只清空当前用户的数据
POST /api/clear
→ 只删除当前用户的记录
```

#### 4. 删除简历
```python
# 旧版：可以删除任何简历
DELETE /api/delete/<id>

# 新版：只能删除自己的简历
DELETE /api/delete/<id>
→ 验证是否属于当前用户
```

## 🎯 用户体验

### 场景演示

**用户 A** 访问系统：
1. 自动获得 Session ID: `abc123...`
2. 上传 3 份简历
3. 只能看到自己的 3 份简历
4. 1小时后数据自动清理

**用户 B** 同时访问：
1. 自动获得 Session ID: `xyz789...`
2. 上传 5 份简历
3. 只能看到自己的 5 份简历
4. **看不到用户A的数据** ✅

### Session 持久化

- ✅ 关闭浏览器重新打开：数据还在（session cookie 保存在浏览器）
- ✅ 刷新页面：数据还在
- ✅ 打开新标签页：共享 session，数据还在
- ❌ 清除浏览器 Cookie：session 丢失，数据无法访问（但1小时后会自动清理）
- ❌ 使用无痕模式/隐私浏览：每次都是新 session

## ⚙️ 配置参数

### 可调整的参数

#### 1. Session 过期时间
```python
# 在 app.py 中修改
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(hours=1)  # 默认1小时
```

#### 2. 清理任务频率
```python
# 在 app.py 中修改
scheduler.add_job(
    func=lambda: db.clean_expired_data(hours=1),
    trigger="interval",
    minutes=10  # 默认每10分钟，可改为5/15/30分钟
)
```

#### 3. 数据保留时间
```python
# 在 database.py 中修改
def clean_expired_data(self, hours: int = 1):  # 默认1小时，可改为2/3/24小时
```

### 环境变量配置

生产环境建议设置 SECRET_KEY：

```bash
# .env 文件或 Render 环境变量
export SECRET_KEY="your-secret-key-here-very-long-and-random"
```

## 🚀 部署注意事项

### 1. 数据库迁移

如果是从旧版本升级：

```python
# 旧数据库没有 session_id 字段
# 系统会自动创建新表结构
# 旧数据将无法访问（因为没有 session_id）
```

**建议**：在升级前备份或清空旧数据库。

### 2. Secret Key 配置

**开发环境**：自动生成随机 key（每次重启会变）

**生产环境**：必须配置固定的 SECRET_KEY

```bash
# Render 环境变量
SECRET_KEY=长随机字符串至少32位
```

生成方式：
```python
import secrets
print(secrets.token_hex(32))
```

### 3. 多实例部署

如果使用多个服务器实例（负载均衡），需要：

- ✅ 配置统一的 SECRET_KEY
- ✅ 使用 Redis Session（可选）
- ✅ 使用共享数据库

## 📈 性能优化

### 1. 数据库索引

已自动创建索引：
```sql
CREATE INDEX idx_session_id ON resumes(session_id);
CREATE INDEX idx_created_at ON resumes(created_at);
```

### 2. 查询效率

- Session ID 查询：O(1) - 使用索引
- 过期数据清理：定期后台执行，不影响用户请求

### 3. 内存占用

- APScheduler 后台线程：~10MB
- Session 存储：基于 Cookie，无服务器内存占用

## 🔒 安全性

### 1. Session 安全
- ✅ Session ID 使用加密 Cookie 存储
- ✅ 使用 secrets.token_urlsafe 生成随机 ID
- ✅ HTTPS 部署时 Cookie 自动加密

### 2. 数据隔离
- ✅ 用户无法访问他人数据
- ✅ 所有查询自动过滤 session_id
- ✅ 删除操作需验证所属用户

### 3. 自动清理
- ✅ 敏感数据不长期保留
- ✅ 符合隐私保护最佳实践

## 📊 监控建议

### 可添加的监控指标

```python
# 统计当前活跃用户数
SELECT COUNT(DISTINCT session_id) FROM resumes;

# 统计每个用户的数据量
SELECT session_id, COUNT(*) as count 
FROM resumes 
GROUP BY session_id;

# 查看最旧的数据
SELECT MIN(created_at) FROM resumes;

# 统计今天清理的数据量
# （需要添加日志记录）
```

## 🎉 总结

这个功能完美解决了线上多用户使用的问题：

✅ **隐私保护**：用户数据完全隔离  
✅ **自动清理**：不占用服务器存储  
✅ **用户友好**：自动识别，无需登录  
✅ **性能优秀**：后台清理，不影响响应速度  

---

**版本**：v2.0 - 多用户隔离版本  
**最后更新**：2025年10月

